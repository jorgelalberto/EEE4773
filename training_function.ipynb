{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TqOt6Sv7AsMi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ro4oYaEmxe4r",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4746, 270000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.load('./data_train.npy').T\n",
    "labels = np.load('./labels_train.npy')\n",
    "data_train, data_val, labels_train, labels_val = train_test_split(dataset, \n",
    "                                                                    labels,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    random_state=0)\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4746, 300, 300, 3), (1187, 300, 300, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_size = data_train.shape[0]\n",
    "data_train_shaped = np.zeros(shape=(data_train_size,300,300,3))\n",
    "for image in range(data_train_size):\n",
    "    one_img = data_train[image].reshape((300, 300, 3))\n",
    "    data_train_shaped[image] = one_img\n",
    "data_train_shaped.shape\n",
    "\n",
    "data_val_size = data_val.shape[0]\n",
    "data_val_shaped = np.zeros(shape=(data_val_size,300,300,3))\n",
    "for image in range(data_val_size):\n",
    "    one_img = data_val[image].reshape((300, 300, 3))\n",
    "    data_val_shaped[image] = one_img\n",
    "\n",
    "data_train_shaped.shape, data_val_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "del dataset\n",
    "del labels\n",
    "del data_train\n",
    "del data_val\n",
    "gc.collect()\n",
    "\n",
    "data_train_shaped = data_train_shaped.astype('uint8')\n",
    "labels_train = labels_train.astype('uint8')\n",
    "data_val_shaped = data_val_shaped.astype('uint8')\n",
    "labels_val = labels_val.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 22:26:46.692075: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-07 22:26:47.233725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79111 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:90:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((data_train_shaped, labels_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((data_val_shaped, labels_val))\n",
    "BATCH_SIZE = 42\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps_per_epoch=int(tf.data.experimental.cardinality(train_dataset))\n",
    "val_steps_per_epoch=int(tf.data.experimental.cardinality(val_dataset))\n",
    "\n",
    "del train_dataset\n",
    "del val_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\", input_shape=(300,300,3)),\n",
    "    tf.keras.layers.RandomRotation(0.1), # Rotates Images +- 0.2rad (11.5deg)\n",
    "    tf.keras.layers.RandomContrast(0.4), #Add contrast from .1 to 1 of original\n",
    "    tf.keras.layers.RandomZoom(-0.6),  # Add RandomZoom layer for a change in perspective\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "19IQ2gqneqmS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE = (300, 300, 3)\n",
    "#from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB7(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  data_augmentation,\n",
    "  base_model,\n",
    "  tf.keras.layers.Conv2D(32, 1, padding='same', activation='selu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='selu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(128, 5, padding='same', activation='selu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='selu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, name=\"outputs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=.0001),#.0001 or less\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 22:27:43.530312: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2023-08-07 22:27:46.127025: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 38s 213ms/step - loss: 2.2479 - accuracy: 0.1909 - val_loss: 1.8284 - val_accuracy: 0.4987\n",
      "Epoch 2/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 1.6257 - accuracy: 0.4579 - val_loss: 1.0798 - val_accuracy: 0.6908\n",
      "Epoch 3/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 1.0789 - accuracy: 0.6477 - val_loss: 0.6803 - val_accuracy: 0.8088\n",
      "Epoch 4/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.7764 - accuracy: 0.7545 - val_loss: 0.5300 - val_accuracy: 0.8399\n",
      "Epoch 5/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.6194 - accuracy: 0.8051 - val_loss: 0.4528 - val_accuracy: 0.8551\n",
      "Epoch 6/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.5591 - accuracy: 0.8312 - val_loss: 0.3902 - val_accuracy: 0.8753\n",
      "Epoch 7/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.4929 - accuracy: 0.8458 - val_loss: 0.3639 - val_accuracy: 0.8804\n",
      "Epoch 8/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.4420 - accuracy: 0.8651 - val_loss: 0.3410 - val_accuracy: 0.8905\n",
      "Epoch 9/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.4081 - accuracy: 0.8795 - val_loss: 0.3252 - val_accuracy: 0.8905\n",
      "Epoch 10/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.3901 - accuracy: 0.8797 - val_loss: 0.3118 - val_accuracy: 0.8997\n",
      "Epoch 11/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.3487 - accuracy: 0.8911 - val_loss: 0.2985 - val_accuracy: 0.9082\n",
      "Epoch 12/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.3573 - accuracy: 0.8847 - val_loss: 0.2885 - val_accuracy: 0.9082\n",
      "Epoch 13/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.3270 - accuracy: 0.9012 - val_loss: 0.2712 - val_accuracy: 0.9124\n",
      "Epoch 14/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.3144 - accuracy: 0.9054 - val_loss: 0.2732 - val_accuracy: 0.9141\n",
      "Epoch 15/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.2967 - accuracy: 0.9142 - val_loss: 0.2652 - val_accuracy: 0.9191\n",
      "Epoch 16/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2901 - accuracy: 0.9140 - val_loss: 0.2669 - val_accuracy: 0.9174\n",
      "Epoch 17/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.2629 - accuracy: 0.9197 - val_loss: 0.2513 - val_accuracy: 0.9191\n",
      "Epoch 18/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.2771 - accuracy: 0.9145 - val_loss: 0.2414 - val_accuracy: 0.9250\n",
      "Epoch 19/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2683 - accuracy: 0.9170 - val_loss: 0.2421 - val_accuracy: 0.9233\n",
      "Epoch 20/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.2579 - accuracy: 0.9176 - val_loss: 0.2340 - val_accuracy: 0.9292\n",
      "Epoch 21/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2448 - accuracy: 0.9250 - val_loss: 0.2375 - val_accuracy: 0.9225\n",
      "Epoch 22/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2429 - accuracy: 0.9260 - val_loss: 0.2398 - val_accuracy: 0.9301\n",
      "Epoch 23/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.2303 - accuracy: 0.9244 - val_loss: 0.2241 - val_accuracy: 0.9292\n",
      "Epoch 24/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2328 - accuracy: 0.9267 - val_loss: 0.2389 - val_accuracy: 0.9242\n",
      "Epoch 25/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2379 - accuracy: 0.9275 - val_loss: 0.2293 - val_accuracy: 0.9259\n",
      "Epoch 26/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2201 - accuracy: 0.9288 - val_loss: 0.2402 - val_accuracy: 0.9275\n",
      "Epoch 27/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2333 - accuracy: 0.9260 - val_loss: 0.2370 - val_accuracy: 0.9225\n",
      "Epoch 28/300\n",
      "113/113 [==============================] - 22s 194ms/step - loss: 0.2186 - accuracy: 0.9311 - val_loss: 0.2229 - val_accuracy: 0.9318\n",
      "Epoch 29/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1966 - accuracy: 0.9345 - val_loss: 0.2277 - val_accuracy: 0.9242\n",
      "Epoch 30/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.2061 - accuracy: 0.9357 - val_loss: 0.2184 - val_accuracy: 0.9318\n",
      "Epoch 31/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.2026 - accuracy: 0.9340 - val_loss: 0.2119 - val_accuracy: 0.9301\n",
      "Epoch 32/300\n",
      "113/113 [==============================] - 21s 183ms/step - loss: 0.2028 - accuracy: 0.9366 - val_loss: 0.2102 - val_accuracy: 0.9309\n",
      "Epoch 33/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.2119 - accuracy: 0.9330 - val_loss: 0.2200 - val_accuracy: 0.9292\n",
      "Epoch 34/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1964 - accuracy: 0.9357 - val_loss: 0.2231 - val_accuracy: 0.9259\n",
      "Epoch 35/300\n",
      "113/113 [==============================] - 21s 183ms/step - loss: 0.1803 - accuracy: 0.9408 - val_loss: 0.2067 - val_accuracy: 0.9360\n",
      "Epoch 36/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1807 - accuracy: 0.9435 - val_loss: 0.2223 - val_accuracy: 0.9368\n",
      "Epoch 37/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1865 - accuracy: 0.9404 - val_loss: 0.2201 - val_accuracy: 0.9309\n",
      "Epoch 38/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1745 - accuracy: 0.9469 - val_loss: 0.2134 - val_accuracy: 0.9343\n",
      "Epoch 39/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1628 - accuracy: 0.9490 - val_loss: 0.2197 - val_accuracy: 0.9360\n",
      "Epoch 40/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1617 - accuracy: 0.9507 - val_loss: 0.2166 - val_accuracy: 0.9343\n",
      "Epoch 41/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1655 - accuracy: 0.9452 - val_loss: 0.2087 - val_accuracy: 0.9368\n",
      "Epoch 42/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1601 - accuracy: 0.9469 - val_loss: 0.2123 - val_accuracy: 0.9368\n",
      "Epoch 43/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1593 - accuracy: 0.9492 - val_loss: 0.2105 - val_accuracy: 0.9385\n",
      "Epoch 44/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1650 - accuracy: 0.9480 - val_loss: 0.2106 - val_accuracy: 0.9343\n",
      "Epoch 45/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1680 - accuracy: 0.9477 - val_loss: 0.2044 - val_accuracy: 0.9343\n",
      "Epoch 46/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1501 - accuracy: 0.9499 - val_loss: 0.2055 - val_accuracy: 0.9368\n",
      "Epoch 47/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1428 - accuracy: 0.9549 - val_loss: 0.2121 - val_accuracy: 0.9351\n",
      "Epoch 48/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1529 - accuracy: 0.9517 - val_loss: 0.2107 - val_accuracy: 0.9385\n",
      "Epoch 49/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1418 - accuracy: 0.9560 - val_loss: 0.2071 - val_accuracy: 0.9385\n",
      "Epoch 50/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1466 - accuracy: 0.9522 - val_loss: 0.2069 - val_accuracy: 0.9393\n",
      "Epoch 51/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1478 - accuracy: 0.9532 - val_loss: 0.2117 - val_accuracy: 0.9360\n",
      "Epoch 52/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1586 - accuracy: 0.9492 - val_loss: 0.2090 - val_accuracy: 0.9385\n",
      "Epoch 53/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1385 - accuracy: 0.9553 - val_loss: 0.2121 - val_accuracy: 0.9393\n",
      "Epoch 54/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1342 - accuracy: 0.9585 - val_loss: 0.2074 - val_accuracy: 0.9377\n",
      "Epoch 55/300\n",
      "113/113 [==============================] - 21s 183ms/step - loss: 0.1230 - accuracy: 0.9606 - val_loss: 0.2114 - val_accuracy: 0.9377\n"
     ]
    }
   ],
   "source": [
    "epochs=300\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs, \n",
    "  callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/300\n",
      "113/113 [==============================] - 34s 207ms/step - loss: 0.1517 - accuracy: 0.9520 - val_loss: 0.2047 - val_accuracy: 0.9360\n",
      "Epoch 56/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1453 - accuracy: 0.9528 - val_loss: 0.2048 - val_accuracy: 0.9368\n",
      "Epoch 57/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1482 - accuracy: 0.9515 - val_loss: 0.2029 - val_accuracy: 0.9360\n",
      "Epoch 58/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1400 - accuracy: 0.9543 - val_loss: 0.2016 - val_accuracy: 0.9368\n",
      "Epoch 59/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1330 - accuracy: 0.9560 - val_loss: 0.2030 - val_accuracy: 0.9360\n",
      "Epoch 60/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1448 - accuracy: 0.9545 - val_loss: 0.2025 - val_accuracy: 0.9385\n",
      "Epoch 61/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1373 - accuracy: 0.9564 - val_loss: 0.2012 - val_accuracy: 0.9385\n",
      "Epoch 62/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1393 - accuracy: 0.9532 - val_loss: 0.1998 - val_accuracy: 0.9385\n",
      "Epoch 63/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1510 - accuracy: 0.9524 - val_loss: 0.2006 - val_accuracy: 0.9377\n",
      "Epoch 64/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1457 - accuracy: 0.9555 - val_loss: 0.2018 - val_accuracy: 0.9377\n",
      "Epoch 65/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1371 - accuracy: 0.9558 - val_loss: 0.2017 - val_accuracy: 0.9368\n",
      "Epoch 66/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1257 - accuracy: 0.9631 - val_loss: 0.2021 - val_accuracy: 0.9377\n",
      "Epoch 67/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1292 - accuracy: 0.9579 - val_loss: 0.1998 - val_accuracy: 0.9385\n",
      "Epoch 68/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1304 - accuracy: 0.9604 - val_loss: 0.2015 - val_accuracy: 0.9360\n",
      "Epoch 69/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1367 - accuracy: 0.9562 - val_loss: 0.1987 - val_accuracy: 0.9377\n",
      "Epoch 70/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1316 - accuracy: 0.9587 - val_loss: 0.1990 - val_accuracy: 0.9360\n",
      "Epoch 71/300\n",
      "113/113 [==============================] - 21s 183ms/step - loss: 0.1202 - accuracy: 0.9627 - val_loss: 0.1976 - val_accuracy: 0.9360\n",
      "Epoch 72/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1313 - accuracy: 0.9602 - val_loss: 0.2009 - val_accuracy: 0.9377\n",
      "Epoch 73/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1279 - accuracy: 0.9589 - val_loss: 0.1998 - val_accuracy: 0.9368\n",
      "Epoch 74/300\n",
      "113/113 [==============================] - 21s 189ms/step - loss: 0.1365 - accuracy: 0.9568 - val_loss: 0.2026 - val_accuracy: 0.9351\n",
      "Epoch 75/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1339 - accuracy: 0.9566 - val_loss: 0.2001 - val_accuracy: 0.9393\n",
      "Epoch 76/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1402 - accuracy: 0.9570 - val_loss: 0.1999 - val_accuracy: 0.9393\n",
      "Epoch 77/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1296 - accuracy: 0.9598 - val_loss: 0.2008 - val_accuracy: 0.9368\n",
      "Epoch 78/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1190 - accuracy: 0.9627 - val_loss: 0.1975 - val_accuracy: 0.9360\n",
      "Epoch 79/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1253 - accuracy: 0.9617 - val_loss: 0.1984 - val_accuracy: 0.9368\n",
      "Epoch 80/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1265 - accuracy: 0.9595 - val_loss: 0.1996 - val_accuracy: 0.9360\n",
      "Epoch 81/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1220 - accuracy: 0.9625 - val_loss: 0.1997 - val_accuracy: 0.9368\n",
      "Epoch 82/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1228 - accuracy: 0.9623 - val_loss: 0.1997 - val_accuracy: 0.9377\n",
      "Epoch 83/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1379 - accuracy: 0.9570 - val_loss: 0.1980 - val_accuracy: 0.9351\n",
      "Epoch 84/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1308 - accuracy: 0.9579 - val_loss: 0.1985 - val_accuracy: 0.9360\n",
      "Epoch 85/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1242 - accuracy: 0.9617 - val_loss: 0.1971 - val_accuracy: 0.9410\n",
      "Epoch 86/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1217 - accuracy: 0.9631 - val_loss: 0.1994 - val_accuracy: 0.9410\n",
      "Epoch 87/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1224 - accuracy: 0.9623 - val_loss: 0.2006 - val_accuracy: 0.9402\n",
      "Epoch 88/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1343 - accuracy: 0.9583 - val_loss: 0.2000 - val_accuracy: 0.9393\n",
      "Epoch 89/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1204 - accuracy: 0.9608 - val_loss: 0.1985 - val_accuracy: 0.9385\n",
      "Epoch 90/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1287 - accuracy: 0.9579 - val_loss: 0.2002 - val_accuracy: 0.9410\n",
      "Epoch 91/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1190 - accuracy: 0.9612 - val_loss: 0.1990 - val_accuracy: 0.9402\n",
      "Epoch 92/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1309 - accuracy: 0.9583 - val_loss: 0.1999 - val_accuracy: 0.9393\n",
      "Epoch 93/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1254 - accuracy: 0.9602 - val_loss: 0.1972 - val_accuracy: 0.9402\n",
      "Epoch 94/300\n",
      "113/113 [==============================] - 20s 181ms/step - loss: 0.1227 - accuracy: 0.9606 - val_loss: 0.1988 - val_accuracy: 0.9393\n",
      "Epoch 95/300\n",
      "113/113 [==============================] - 21s 182ms/step - loss: 0.1255 - accuracy: 0.9631 - val_loss: 0.1994 - val_accuracy: 0.9402\n"
     ]
    }
   ],
   "source": [
    "# second pass\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=.00001),#.0001 or less\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "epochs=300\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  initial_epoch=history.epoch[-1],\n",
    "  epochs=epochs, \n",
    "  callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 4s - loss: 0.1971 - accuracy: 0.9410 - 4s/epoch - 139ms/step\n",
      "Restored model, accuracy: 94.10%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_ds, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 16s - loss: 0.0488 - accuracy: 0.9853 - 16s/epoch - 141ms/step\n",
      "Restored model, accuracy: 98.53%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(train_ds, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  813\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 700\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "113/113 [==============================] - 38s 237ms/step - loss: 0.1869 - accuracy: 0.9610 - val_loss: 0.4280 - val_accuracy: 0.9309\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 24s 212ms/step - loss: 0.1806 - accuracy: 0.9610 - val_loss: 0.2968 - val_accuracy: 0.9419\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 24s 212ms/step - loss: 0.1048 - accuracy: 0.9741 - val_loss: 0.1809 - val_accuracy: 0.9621\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 24s 210ms/step - loss: 0.0830 - accuracy: 0.9806 - val_loss: 0.1945 - val_accuracy: 0.9604\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 24s 212ms/step - loss: 0.1058 - accuracy: 0.9753 - val_loss: 0.1791 - val_accuracy: 0.9663\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0687 - accuracy: 0.9834 - val_loss: 0.2022 - val_accuracy: 0.9638\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 24s 212ms/step - loss: 0.0593 - accuracy: 0.9855 - val_loss: 0.1726 - val_accuracy: 0.9705\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 24s 212ms/step - loss: 0.0467 - accuracy: 0.9895 - val_loss: 0.1400 - val_accuracy: 0.9747\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0581 - accuracy: 0.9861 - val_loss: 0.1695 - val_accuracy: 0.9671\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0344 - accuracy: 0.9909 - val_loss: 0.2481 - val_accuracy: 0.9638\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0592 - accuracy: 0.9838 - val_loss: 0.2134 - val_accuracy: 0.9621\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0403 - accuracy: 0.9909 - val_loss: 0.1859 - val_accuracy: 0.9663\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0732 - accuracy: 0.9834 - val_loss: 0.1820 - val_accuracy: 0.9705\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0433 - accuracy: 0.9888 - val_loss: 0.1997 - val_accuracy: 0.9612\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0561 - accuracy: 0.9874 - val_loss: 0.2275 - val_accuracy: 0.9604\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 24s 211ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.1880 - val_accuracy: 0.9697\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 24s 210ms/step - loss: 0.0276 - accuracy: 0.9928 - val_loss: 0.1954 - val_accuracy: 0.9663\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 24s 212ms/step - loss: 0.0493 - accuracy: 0.9890 - val_loss: 0.2071 - val_accuracy: 0.9655\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save('NocturnaEmblemClassifierV3.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 300, 300, 3)       0         \n",
      "                                                                 \n",
      " efficientnetb7 (Functional)  (None, 10, 10, 2560)     64097687  \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 10, 10, 32)        81952     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 10, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 5, 5, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 5, 32)          9248      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2, 128)         102528    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,309,217\n",
      "Trainable params: 63,458,542\n",
      "Non-trainable params: 850,675\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 4s - loss: 0.1400 - accuracy: 0.9747 - 4s/epoch - 139ms/step\n",
      "Restored model, accuracy: 97.47%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_ds, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 16s - loss: 0.0116 - accuracy: 0.9977 - 16s/epoch - 141ms/step\n",
      "Restored model, accuracy: 99.77%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(train_ds, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
